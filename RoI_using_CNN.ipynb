{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T11:24:28.779082Z",
     "start_time": "2019-10-29T11:24:28.771072Z"
    }
   },
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "# import plots_help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from models import LinkNet34\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image, ImageFilter\n",
    "import time\n",
    "import sys\n",
    "import ssl\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LinkNet34()\n",
    "# model.load_state_dict(torch.load('linknet.pth'))\n",
    "model.load_state_dict(torch.load('linknet.pth', map_location=lambda storage, loc: storage))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LinkNet34()\n",
    "# model.load_state_dict(torch.load('linknet.pth'))\n",
    "model.load_state_dict(torch.load('linknet.pth', map_location=lambda storage, loc: storage))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T12:53:31.632335Z",
     "start_time": "2019-10-27T12:53:25.631121Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "from scipy import ndarray\n",
    "import skimage as sk\n",
    "from skimage import transform\n",
    "from skimage import util\n",
    "\n",
    "def random_rotation(image_array: ndarray):\n",
    "    # pick a random degree of rotation between 25% on the left and 25% on the right\n",
    "    random_degree = random.uniform(-25, 25)\n",
    "    return sk.transform.rotate(image_array, random_degree)\n",
    "\n",
    "def random_noise(image_array: ndarray):\n",
    "    # add random noise to the image\n",
    "    return sk.util.random_noise(image_array)\n",
    "\n",
    "def horizontal_flip(image_array: ndarray):\n",
    "    # horizontal flip doesn't need skimage, it's easy as flipping the image array of pixels !\n",
    "    return image_array[:, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T10:54:48.379441Z",
     "start_time": "2019-10-30T10:54:47.521668Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T12:39:23.414686Z",
     "start_time": "2019-10-29T12:39:23.407850Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#calculates frame rate of a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T11:34:10.175349Z",
     "start_time": "2019-10-30T11:34:10.166372Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second  : 29.948009\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "def frame_ps_video(DEFAULT_VIDEO):\n",
    "    video = cv2.VideoCapture(DEFAULT_VIDEO)\n",
    "\n",
    "\n",
    "    (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "\n",
    "    if int(major_ver)  < 3 :\n",
    "        fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "\n",
    "        print( \"Frames per second : {0}\".format(fps))\n",
    "        video.release()\n",
    "        return fps\n",
    "    else :\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        print( \"Frames per second  : {0}\".format(fps))\n",
    "        video.release()\n",
    "        return fps\n",
    "\n",
    "eye_remove = True\n",
    "#can change to true/false\n",
    "\n",
    "CASCADE_PATH = \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "#DEFAULT_VIDEO = \"C:\\\\Users\\\\Jayant\\\\Desktop\\\\ML_mini_prj\\\\subject27\\\\vid.avi\"  #true val-89bpm\n",
    "DEFAULT_VIDEO = \"/Users/tgit/Desktop/mahika/sem6/ml/ML_Proj/rppgVitalMeasurments/UBFC_DATASET/DATASET_2/subject42/vid.avi\" #true val-110 bpm \n",
    "\n",
    "\n",
    "MIN_FACE_SIZE = 100\n",
    "\n",
    "WIDTH_FRACTION = 0.8 # Fraction of bounding box width to include in ROI\n",
    "HEIGHT_FRACTION = 1\n",
    "\n",
    "FPS = frame_ps_video(DEFAULT_VIDEO)\n",
    "jojo=8   #window_time_sec initialize\n",
    "\n",
    "if FPS>=20 and FPS<25:\n",
    "    jojo=10\n",
    "elif FPS>=25 and FPS<=32 :\n",
    "    jojo=30\n",
    "elif FPS>32:\n",
    "    jojo=20\n",
    "\n",
    "WINDOW_TIME_SEC = jojo\n",
    "\n",
    "WINDOW_SIZE = int(np.ceil(WINDOW_TIME_SEC * FPS))\n",
    "MIN_HR_BPM = 50.0\n",
    "MAX_HR_BMP = 240.0\n",
    "MAX_HR_CHANGE = 12.0\n",
    "SEC_PER_MIN = 60\n",
    "\n",
    "EYE_LOWER_FRAC = 0.35\n",
    "EYE_UPPER_FRAC = 0.5\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T11:34:13.101502Z",
     "start_time": "2019-10-30T11:34:13.095519Z"
    }
   },
   "outputs": [],
   "source": [
    "def roi_util(image, faceBox): \n",
    "\n",
    "    widthFrac = WIDTH_FRACTION\n",
    "    heigtFrac = HEIGHT_FRACTION\n",
    "\n",
    "    # Adjust bounding box\n",
    "    (x, y, w, h) = faceBox\n",
    "    widthOffset = int((1 - widthFrac) * w / 2)\n",
    "    heightOffset = int((1 - heigtFrac) * h / 2)\n",
    "    faceBoxAdjusted = (x + widthOffset, y + heightOffset,int(widthFrac * w), int(heigtFrac * h))\n",
    "    (x, y, w, h) = faceBoxAdjusted\n",
    "    backgrndMask = np.full(image.shape, True, dtype=bool)\n",
    "    backgrndMask[y:y+h, x:x+w, :] = False \n",
    "\n",
    "    if eye_remove:\n",
    "        backgrndMask[int(y + h * EYE_LOWER_FRAC) :int( y + h * EYE_UPPER_FRAC), :] = True\n",
    "\n",
    "\n",
    "    roi = np.ma.array(image, mask=backgrndMask) # Masked array\n",
    "    return roi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T11:34:14.061405Z",
     "start_time": "2019-10-30T11:34:14.055420Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Sum of square differences between x1, x2, y1, y2 points for each ROI\n",
    "\n",
    "\n",
    "def distance(roi1, roi2):\n",
    "    return sum((roi1[i] - roi2[i])**2 for i in range(len(roi1)))\n",
    "\n",
    "def roi_extract(frame, faceCascade, previousFaceBox):\n",
    "    grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(grey, scaleFactor=1.1,minNeighbors=5, minSize=(MIN_FACE_SIZE, MIN_FACE_SIZE), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    roi = None\n",
    "    faceBox = None\n",
    "\n",
    "    # If no face detected, use ROI from previous frame\n",
    "    if len(faces) == 0:\n",
    "        faceBox = previousFaceBox\n",
    "\n",
    "    # if many faces detected, use one closest to that from previous frame\n",
    "    #standard way\n",
    "    elif len(faces) > 1:\n",
    "        if previousFaceBox is not None:\n",
    "            # Find closest\n",
    "            minDist = float(\"inf\")\n",
    "            for face in faces:\n",
    "                if distance(previousFaceBox, face) < minDist:\n",
    "                    faceBox = face\n",
    "        else:\n",
    "            # Chooses largest box by area \n",
    "            maxArea = 0\n",
    "            for face in faces:\n",
    "                if (face[2] * face[3]) > maxArea:\n",
    "                    faceBox = face\n",
    "\n",
    "    # If only one face dectected\n",
    "    else:\n",
    "        faceBox = faces[0]\n",
    "\n",
    "        # Show rectangle\n",
    "        #(x, y, w, h) = faceBox\n",
    "        #cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 255, 255), 2)\n",
    "    if faceBox is not None:\n",
    "        roi = roi_util(frame, faceBox)\n",
    "    return faceBox, roi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T11:34:14.988819Z",
     "start_time": "2019-10-30T11:34:14.983796Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_heartrate(window, lastHR):\n",
    "    # Normalize across the window to have zero-mean and unit variance\n",
    "    mean = np.mean(window, axis=0)\n",
    "    std = np.std(window, axis=0)\n",
    "    normalized = (window - mean) / std\n",
    "\n",
    "    # decompose into three source signals using ICA\n",
    "    ica = FastICA(tol=0.01,n_components=3)\n",
    "    srcSig = ica.fit_transform(normalized)\n",
    "\n",
    "    # pca = PCA()\n",
    "    # srcSig = pca.fit_transform(normalized)\n",
    "    #uncommment to decompose using PCA\n",
    "\n",
    "    # Find power spectrum\n",
    "    powerSpec = np.abs(np.fft.fft(srcSig, axis=0))**2\n",
    "    freqs = np.fft.fftfreq(WINDOW_SIZE, 1.0 / FPS)\n",
    "\n",
    "    # Find heart rate\n",
    "    maxPwrSrc = np.max(powerSpec, axis=1)\n",
    "    validIdx = np.where((freqs >= MIN_HR_BPM / SEC_PER_MIN) & (freqs <= MAX_HR_BMP / SEC_PER_MIN))\n",
    "    validPwr = maxPwrSrc[validIdx]\n",
    "    validFreqs = freqs[validIdx]\n",
    "    maxPwrIdx = np.argmax(validPwr)\n",
    "    hr = validFreqs[maxPwrIdx]\n",
    "#     print (hr) #printing heart beats/sec as time window slides\n",
    "\n",
    "    # plot\n",
    "    print(\"Recorded: \"+str(hr))\n",
    "    return hr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T11:35:19.694295Z",
     "start_time": "2019-10-30T11:34:16.077723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.5990038175750834\n",
      "Recorded: 1.5990038175750834\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.665628976640712\n",
      "Recorded: 1.665628976640712\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.665628976640712\n",
      "Recorded: 1.665628976640712\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/decomposition/fastica_.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "calculating hr...\n",
      "extracting heartrate...\n",
      "1.6323163971078978\n",
      "Recorded: 1.6323163971078978\n",
      "\n",
      "just a theoretical mean  97.99023394883207\n",
      "\n",
      "Instances captured -- 39\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "video = cv2.VideoCapture(DEFAULT_VIDEO)\n",
    "faceCascade = cv2.CascadeClassifier(CASCADE_PATH)\n",
    "\n",
    "colorSig = [] # Will store the average RGB color values in each frame's ROI\n",
    "heartRates = [] # Will store the heart rate calculated every 1 second\n",
    "previousFaceBox = None\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "#     previousFaceBox, roi = roi_extract(frame, faceCascade, previousFaceBox)\n",
    "#     print(roi.shape)\n",
    "    \n",
    "    #face segmenation - cnn pre-trained resnet\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    img_transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    shape = frame.shape[0:2]\n",
    "    frame_ = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_ = cv2.resize(frame_,(256,256), cv2.INTER_LINEAR )\n",
    "    \n",
    "    a = img_transform(Image.fromarray(frame_))\n",
    "    a = a.unsqueeze(0)\n",
    "    imgs = Variable(a.to(dtype=torch.float, device=device))\n",
    "    pred = model(imgs)\n",
    "\n",
    "    pred = torch.nn.functional.interpolate(pred, size=[shape[0], shape[1]])\n",
    "    mask = pred.data.cpu().numpy()\n",
    "    mask = mask.squeeze()\n",
    "\n",
    "    mask = mask > 0.8\n",
    "    rgba = cv2.cvtColor(frame, cv2.COLOR_BGR2BGRA)\n",
    "    ind = frame[np.where(mask != 0)]\n",
    "    non_mask_ind = np.where(mask == 0) #places outside face mask\n",
    "    rgba[non_mask_ind] = [0,0,0,0]\n",
    "    roi = rgba\n",
    "\n",
    "    \n",
    "    #print(previousFaceBox) #eg--[275 181 160 160]\n",
    "#     cc=1\n",
    "#     if(cc==1):\n",
    "#         print(roi)\n",
    "#         cc+=1\n",
    "\n",
    "    if (roi is not None) and (np.size(roi) > 0):\n",
    "        colorChannels = roi.reshape(-1, roi.shape[-1])\n",
    "        avgColor = colorChannels.mean(axis=0)\n",
    "        colorSig.append(avgColor)\n",
    "\n",
    "    # Calculate heart rate every one second (once have 10sec or 15 sec or 20 sec of data depends on jojo)\n",
    "    if (len(colorSig) >= WINDOW_SIZE) and (len(colorSig) % np.ceil(FPS) == 0):\n",
    "        windowStart = len(colorSig) - WINDOW_SIZE\n",
    "        window = colorSig[windowStart : windowStart + WINDOW_SIZE]\n",
    "        lastHR = heartRates[-1] if len(heartRates) > 0 else None\n",
    "        heartRates.append(extract_heartrate(window, lastHR))\n",
    "\n",
    "#     if np.ma.is_masked(roi):\n",
    "#         roi = np.where(roi.mask == True, 0, roi)\n",
    "    \n",
    "    cv2.imshow('Image',roi)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "print()\n",
    "print( \"just a theoretical mean \",np.mean(heartRates)*60)\n",
    "print()\n",
    "print(\"Instances captured --\",len(heartRates))\n",
    " \n",
    "pd.DataFrame(heartRates).to_csv(\"result_bps.csv\")\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
